{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on Topic 18 and 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 18 Intro to Ling Reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coeff. of Deter.\n",
    "- \"R-Squared\": =statistical **measure** that is used to assess the **goodness of fit** of a regression model\n",
    "- \"R^2\"% of the variations in y are explained by the X in our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T15:11:02.727029Z",
     "start_time": "2021-01-13T15:11:02.724399Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_reg(X, Y, Y_pred):\n",
    "    plt.scatter(X, Y, label='data')\n",
    "    plt.plot(X, Y_pred, label='regression line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumptions for LinReg\n",
    "- Linearity: requires that there is a linear relationship between y and X. Linear means that the change in Y by 1-unit change in X, is constant\n",
    "    - Can best be tested with scatter plots\n",
    "- Normality: model residuals should follow a normal distribution\n",
    "    - Check with histograms or a Q-Q-Plots\n",
    "- Homoscedasticity (AKA homoskedasticity): y's variability is equal across the range of values of X\n",
    "    - Check with scatter plot with y on y-axis, or use significance tests like Breusch-Pagan / Cook-Weisberg test or White general test to detect this phenomenon. Remember that, if these tests give you a p-value < 0.05, the null hypothesis can rejected, and you can assume the data is heteroscedastic.\n",
    "- check for Linearity and Homoscedasticity in the residuals as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLS in Statsmodels\n",
    "- for model summary shown on bottom of this page\n",
    "- sm.graphics.plot_regress_exog(model, \"height\", fig=fig) plots shown on bottom of page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "model = ols(formula=f, data=df).fit()\n",
    "model.summary()\n",
    "\n",
    "import statsmodels.api as sm\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "fig = sm.graphics.plot_regress_exog(model, \"height\", fig=fig)\n",
    "# This plots four graphs in a 2 by 2 figure: ‘endog versus exog’,\n",
    "# ‘residuals versus exog’, ‘fitted versus exog’ and ‘fitted plus residual versus exog’\n",
    "\n",
    "import scipy.stats as stats\n",
    "residuals = model.resid\n",
    "fig = sm.graphics.qqplot(residuals, dist=stats.norm, line='45', fit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLS in Statsmodels Lab\n",
    "- Step 1: Read the dataset and inspect its columns and 5-point statistics\n",
    "- Step 2: Plot histograms with kde overlay to check the distribution of the predictors\n",
    "- Step 3: Test for the linearity assumption \n",
    "- Step 4: Run a simple regression in Statsmodels with TV as a predictor and get Reg Diagnostics summary\n",
    "- Step 5: Draw a prediction line with data points on a scatter plot for X (TV) and Y (Sales)\n",
    "- Step 6: Visualize the error term for variance and heteroscedasticity\n",
    "- Step 7: Check the normality assumptions by creating a QQ-plot\n",
    "- Step 8: Repeat the above for radio and record your observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T15:39:57.097380Z",
     "start_time": "2021-01-13T15:39:56.554038Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 2\n",
    "for column in data:\n",
    "    data[column].plot.hist(density=True, label = column+' histogram')\n",
    "    data[column].plot.kde(label =column+' kde')\n",
    "    plt.legend()\n",
    "\n",
    "# Step 3\n",
    "fig, axs = plt.subplots(1, 3, sharey=True, figsize=(18, 6))\n",
    "for idx, channel in enumerate(['TV', 'radio', 'newspaper']):\n",
    "    data.plot(kind='scatter', x=channel, y='sales', ax=axs[idx], label=channel)\n",
    "plt.legend()\n",
    "\n",
    "# Step 4\n",
    "import statsmodels.formula.api as smf\n",
    "# create a fitted model in one line\n",
    "model = smf.ols(formula=f, data=data).fit()\n",
    "model.summary()\n",
    "\n",
    "# Step 5\n",
    "# create a DataFrame with the minimum and maximum values of TV\n",
    "X_new = pd.DataFrame({'TV': [data.TV.min(), data.TV.max()]})\n",
    "print(X_new.head())\n",
    "# make predictions for those x values and store them\n",
    "preds = model.predict(X_new)\n",
    "# first, plot the observed data and the least squares line\n",
    "data.plot(kind='scatter', x='TV', y='sales')\n",
    "plt.plot(X_new, preds, c='red', linewidth=2)\n",
    "\n",
    "# Step 6\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "fig = sm.graphics.plot_regress_exog(model, \"TV\", fig=fig)\n",
    "\n",
    "# Step 7\n",
    "residuals = model.resid\n",
    "fig = sm.graphics.qqplot(residuals, dist=stats.norm, line='45', fit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Diagnostics in Statsmodels\n",
    "- Normality check Q-Q plots (AKA normal density plots)\n",
    "    - can relate q-q plots to hist/kde's\n",
    "- Normality check (Jarque-Bera Test)\n",
    "    - inspects the skewness and kurtosis of data to see if it matches a normal distribution\n",
    "    - Q-Q Plots can become unreliable when your sample size is large\n",
    "    - Null Hypo is Normality\n",
    "- Heteroscedasticity check (Goldfeld-Quandt test AKA GQ test)\n",
    "    - used in regression analysis to check for homoscedasticity in the error terms\n",
    "    - checks if you can define a point that can be used to **differentiate** the variance of the error term\n",
    "    - assumes data is normally distributed, so check before\n",
    "    - null hypothesis is homoscedasticity, larger F-stat means more evidence against null hypothesis and more likely we see different variance for the two groups\n",
    "    - Null Hypo is Homoscedasticity\n",
    "- Heteroscedasticity check (Breush-Pagan Test and White’s Test)\n",
    "    - Statsmodel also offers newer tests for heteroscadasticity including the [Breush-Pagan Test](https://www.statsmodels.org/devel/generated/statsmodels.stats.diagnostic.het_breuschpagan.html) and [White’s Test](https://www.statsmodels.org/dev/generated/statsmodels.stats.diagnostic.het_white.html#statsmodels.stats.diagnostic.het_white) which may be advantageous in certain cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking for Linearity: Joint Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x= <column>, y= <column>, data=<dataset>, kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking for Normality: QQ-plot and JB Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "fig = sm.graphics.qqplot(model.resid, dist=stats.norm, line='45', fit=True)\n",
    "# How to run JB test on its own/ also in model summary\n",
    "name = ['Jarque-Bera','Prob','Skew', 'Kurtosis']\n",
    "test = sms.jarque_bera(model.resid)\n",
    "list(zip(name, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking for Homoscedasticity: GQ Test and viewing scatter plot\n",
    "In the image below, you can see how observations are split into two groups. Next, a test statistic is run through taking the ratio of mean square residual errors for the regressions on the two subsets. Evidence of heteroscedasticity is based on performing a hypothesis test (more on this later) as shown in the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what GQ plot looks like\n",
    "lwr_thresh = data.TV.quantile(q=.45)\n",
    "upr_thresh = data.TV.quantile(q=.55)\n",
    "middle_10percent_indices = data[(data.TV >= lwr_thresh) & (data.TV<=upr_thresh)].index\n",
    "# len(middle_10percent_indices)\n",
    "\n",
    "indices = [x-1 for x in data.index if x not in middle_10percent_indices]\n",
    "plt.scatter(data.TV.iloc[indices], model.resid.iloc[indices])\n",
    "plt.xlabel('TV')\n",
    "plt.ylabel('Model Residuals')\n",
    "plt.title(\"Residuals versus TV Feature\")\n",
    "plt.vlines(lwr_thresh, ymax=8, ymin=-8, linestyles='dashed',linewidth=2)\n",
    "plt.vlines(upr_thresh, ymax=8, ymin=-8, linestyles='dashed',linewidth=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a brief description of the steps involved:\n",
    "\n",
    "* Order the data in ascending order \n",
    "* Split your data into _three_ parts and drop values in the middle part.\n",
    "* Run separate regression analyses on two parts. After each regression, find the Residual Sum of Squares.\n",
    "* Calculate the ratio of the Residual sum of squares of two parts.\n",
    "* Apply the F-test. \n",
    "\n",
    "[Here](https://en.wikipedia.org/wiki/F-test) is a quick introduction to F-test\n",
    "\n",
    "For now, you should just remember that high F values typically indicate that the variances are different. If the error term is homoscedastic, there should be no systematic difference between residuals and F values will be small.\n",
    "However, if the standard deviation of the distribution of the error term is proportional to the x variable, one part will generate a higher sum of square values than the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Goldfeld Quandt test\n",
    "name = ['F statistic', 'p-value']\n",
    "test = sms.het_goldfeldquandt(model.resid.iloc[indices], model.model.exog[indices])\n",
    "list(zip(name, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View heteroscedaasticity\n",
    "plt.scatter(model.predict(df[x_cols]), model.resid)\n",
    "plt.plot(model.predict(df[x_cols]), [0 for i in range(len(df))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ex. of model refining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex. of removing outliers, model refining (then you would check normality and homoscadasticity like above)\n",
    "#Finding a cutoff point\n",
    "for i in range(85, 99):\n",
    "    q = i / 100\n",
    "    print('{} percentile: {}'.format(q, df['MPG_Highway'].quantile(q=q)))\n",
    "subset = df[df['MPG_Highway'] < 38]\n",
    "print('Percent removed:',(len(df) - len(subset))/len(df))\n",
    "outcome = 'MPG_Highway'\n",
    "x_cols = ['Passengers', 'Wheelbase', 'Weight', 'Fueltank']\n",
    "predictors = '+'.join(x_cols)\n",
    "formula = outcome + '~' + predictors\n",
    "model = ols(formula=formula, data=subset).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(np.abs(stats.zscore(df)) < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting Significance and P-values \n",
    "\n",
    "##### Hypothesis Testing in Regression \n",
    "\n",
    "During regression, you try to measure the model parameters (coefficients). The null and alternative hypotheses are also set up in those terms.\n",
    "- **Null Hypothesis ($H_0$)**: There is no relationship between X and y\n",
    "\n",
    "- **Alternative Hypothesis ($H_a$):** There is \"some\" relation between X and y\n",
    "\n",
    "- p-value as a level of statistical significance\n",
    "    - represents a **probability of observing your results (or something more extreme) given that the null hypothesis is true** and the probability that the coefficient is actually zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found in model summary P > |t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 19 Multi Lin Reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLR\n",
    "- $$ \\hat y = \\hat\\beta_0 + \\hat\\beta_1 x_1 + \\hat\\beta_2 x_2 +\\ldots + \\hat\\beta_n x_n $$\n",
    "- fitted line, slope parameters, intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with Cat Vars\n",
    "- Identifying Cat Vars\n",
    "- Transforming Cat Vars\n",
    "    - Label encoding: represent labels as numbers\n",
    "    - Creating Dummy Vars / One Hot Encoding: create each category into a new column and have 1 or 0 (required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter matrix (usually done on con. vars.)\n",
    "pd.plotting.scatter_matrix(data, figsize=(12,15));\n",
    "# indidual scattter plots with y on y-axis\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(16,3))\n",
    "for xcol, ax in zip(['acceleration', 'displacement', 'horsepower', 'weight'], axes):\n",
    "    data.plot(kind='scatter', x=xcol, y='mpg', ax=ax, alpha=0.4, color='b')\n",
    "# histograms\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.gca()\n",
    "data.hist(ax = ax);\n",
    "\n",
    "# Label Encoding\n",
    "origin = ['USA', 'EU', 'EU', 'ASIA','USA', 'EU', 'EU', 'ASIA', 'ASIA', 'USA']\n",
    "origin_series = pd.Series(origin).astype('category')\n",
    "origin_series.cat.codes\n",
    "# or \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_make = LabelEncoder()\n",
    "origin_encoded = lb_make.fit_transform(origin_series) # .astype('category') not required\n",
    "\n",
    "# Creating Dummy Vars (w/o avoiding DV trap)\n",
    "pd.get_dummies(origin_series)\n",
    "# or\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "origin_dummies = lb.fit_transform(origin_series)\n",
    "# You need to convert this back to a dataframe\n",
    "origin_dum_df = pd.DataFrame(origin_dummies,columns=lb.classes_)\n",
    "origin_dum_df\n",
    "\n",
    "# Creating Dummy Vars (avoiding DV trap)\n",
    "pd.get_dummies(origin_series, drop_first=True)\n",
    "# The dropped category becomes the reference category. The coeffs resulting\n",
    "# from remaining variables represent the change relative to the reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with Cat Vars Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picking and plotting cat vars with y on y-axis\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(16,10), sharey=True)\n",
    "categoricals = ['BldgType', 'KitchenQual', 'SaleType', 'MSZoning', 'Street', 'Neighborhood']\n",
    "for col, ax in zip(categoricals, axes.flatten()):\n",
    "    (ames.groupby(col)               # group values together by column of interest\n",
    "         .mean()['SalePrice']        # take the mean of the saleprice for each group\n",
    "         .sort_values()              # sort the groups in ascending order\n",
    "         .plot\n",
    "         .bar(ax=ax))                # create a bar graph on the ax\n",
    "    ax.set_title(col)\n",
    "fig.tight_layout()\n",
    "# Create dummy variables for your six categorical features\n",
    "dummies = pd.get_dummies(ames[categoricals], prefix=categoricals, drop_first=True)\n",
    "ames_preprocessed = ames.drop(categoricals, axis=1)\n",
    "ames_preprocessed = pd.concat([ames_preprocessed, dummies], axis=1)\n",
    "ames_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multicollinearity\n",
    "- Identifying multicollinearity:\n",
    "- address (drop necessary columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indetifying multicollinearity\n",
    "pd.plotting.scatter_matrix(data_pred,figsize  = [9, 9]);\n",
    "# or \n",
    "# save absolute value of correlation matrix as a data frame\n",
    "# converts all values to absolute value\n",
    "# stacks the row:column pairs into a multindex\n",
    "# reset the index to set the multindex to seperate columns\n",
    "# sort values. 0 is the column automatically generated by the stacking\n",
    "df=data_pred.corr().abs().stack().reset_index().sort_values(0, ascending=False)\n",
    "# zip the variable name columns (Which were only named level_0 and level_1 by default) in a new column named \"pairs\"\n",
    "df['pairs'] = list(zip(df.level_0, df.level_1))\n",
    "# set index to pairs\n",
    "df.set_index(['pairs'], inplace = True)\n",
    "#d rop level columns\n",
    "df.drop(columns=['level_1', 'level_0'], inplace = True)\n",
    "# rename correlation column as cc rather than 0\n",
    "df.columns = ['cc']\n",
    "# drop duplicates. This could be dangerous if you have variables perfectly correlated with variables other than themselves.\n",
    "df.drop_duplicates(inplace=True)\n",
    "df[(df.cc>.75) & (df.cc <1)]\n",
    "# or \n",
    "abs(ames_preprocessed.corr()) > 0.75 # or annotated heat map\n",
    "# or \n",
    "import seaborn as sns\n",
    "sns.heatmap(data_pred.corr(), center=0); # coolwarm cmap and true annot\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "X = df[x_cols]\n",
    "vif = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "list(zip(x_cols, vif))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Trans\n",
    "- helps x's approach normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_normal = ['displacement', 'horsepower', 'weight']\n",
    "for feat in non_normal:\n",
    "    data[feat] = data[feat].map(lambda x: np.log(x))\n",
    "pd.plotting.scatter_matrix(data[x_cols], figsize=(10,12));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling and Normalization\n",
    "- Popular transformations listed at the bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = data['acceleration']\n",
    "disp = data['displacement']\n",
    "horse = data['horse']\n",
    "weight = data['weight']\n",
    "\n",
    "minmax_acc = (acc - min(acc)) / (max(acc) - min(acc)) # min max scaling\n",
    "log_disp = np.log(disp)\n",
    "standard_weight = (weight - np.mean(weight)) / np.sqrt(np.var(weight)) # standardization\n",
    "meannorm_scaled_horse = (horse - np.mean(horse)) / (max(horse) - min(horse)) # mean normalization\n",
    "\n",
    "data_scaled['acc'] = minmax_acc\n",
    "data_scaled['disp'] = log_disp\n",
    "data_scaled['horse'] = scaled_horse\n",
    "data_scaled['weight'] = standard_weight\n",
    "data_scaled.hist(figsize = [6, 6]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling and Normalization Lab\n",
    "- Look at hists for cont vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_data = ames.loc[:, ((ames.dtypes != 'object') & (ames.nunique() > 20))]\n",
    "fig, axes = plt.subplots(nrows=(con_data.shape[1] // 3), ncols=3, figsize=(16,40))\n",
    "convars = [column for column in con_data.columns if column != 'Id']\n",
    "for col, ax in zip(convars, axes.flatten()):\n",
    "    ax.hist(ames[col].dropna(), bins='auto')\n",
    "    ax.set_title(col)  \n",
    "fig.tight_layout()\n",
    "# Select non zero-inflated continuous features as ames_cont\n",
    "ames_cont = ames[['LotFrontage', 'LotArea', 'YearBuilt', '1stFlrSF', 'GrLivArea', 'SalePrice']]\n",
    "ames_cont.hist(figsize  = [8, 8], bins='auto');\n",
    "# Perform log trans\n",
    "import numpy as np\n",
    "log_names = [f'{column}_log' for column in ames_cont.columns]\n",
    "ames_log = np.log(ames_cont)\n",
    "ames_log.columns = log_names\n",
    "ames_log.hist(figsize=(10, 10), bins='auto')\n",
    "fig.tight_layout();\n",
    "# standardize\n",
    "def standardize(feature):\n",
    "    return (feature - feature.mean()) / feature.std()\n",
    "features_final = ames_log.apply(standardize)\n",
    "features_final.hist(figsize  = [8, 8], bins='auto');\n",
    "\n",
    "# plotting before/after feature scaling\n",
    "def plots(df, col, t):\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(121)\n",
    "    sns.kdeplot(df[col])\n",
    "    plt.title('Before' + str(t).split('(')[0]) \n",
    "    \n",
    "    plt.subplot(122)\n",
    "    p1 = t.fit_transform(df[[col]]).flatten()\n",
    "    sns.kdeplot(p1)\n",
    "    plt.title('After' + str(t).split('(')[0])    \n",
    "    \n",
    "for col in df_m1_conts.columns:\n",
    "    plots(df_m1_conts.copy(), col, MinMaxScaler())\n",
    "    \n",
    "for col in df_m1_conts.columns:\n",
    "    plots(df_m1_conts.copy(), col, StandardScaler())\n",
    "    \n",
    "# scaling \n",
    "minmax = MinMaxScaler()\n",
    "stndrd = StandardScaler()\n",
    "minmax.fit_transform(df[[col]])\n",
    "stndrd.fit_transform(df[[col]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLR in Statsmodels and SKLearn\n",
    "- Interpretation: coeffs interpreted as \"how does Y change for each additional unit X\" where X is the (log- and min-max, standardized,...) transformed data matrix.\n",
    "- sklearn coeffs may be different from statsmodels, but they should return equivalent results.\n",
    "\n",
    "The extimates for the categorical variables are the same \"up to a constant\", the difference between the categorical variables is added in the intercept!\n",
    "\n",
    "You can make sure to get the same result in both Statsmodels and Scikit-learn, by dropping out one of the `orig_`-levels. This way, you're essentially forcing the coefficient of this level to be equal to zero, and the intercepts and the other coefficients will be the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df for model\n",
    "data_ols = pd.concat([mpg, scaled_acc, scaled_weight, orig_dummies], axis= 1)\n",
    "data_ols.head()\n",
    "# baseline model\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "y = 'mpg'\n",
    "X = data_ols.drop('mpg', axis=1)\n",
    "X_cols = \"+\".join(X.columns)\n",
    "formula = y + \"~\" + X_cols\n",
    "model = ols(formula= formula, data=data_train).fit()\n",
    "# or \n",
    "X_train = sm.add_constant(X_train)\n",
    "model = sm.OLS(y_train,X_train).fit()\n",
    "model.summary()\n",
    "# or sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "y = data_ols['mpg']\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "linreg.coef_\n",
    "linreg.intercept_\n",
    "yhat = linreg.predict(X_test)\n",
    "# to get same coeffs and intercepts as statsmodels\n",
    "X_train = X.drop(\"orig_3\",axis=1)\n",
    "linreg.fit(X_train, y_train)\n",
    "linreg.coef_\n",
    "linreg.intercept_\n",
    "X_cols = \"+\".join(predictors.columns)\n",
    "formula = y + \"~\" + X_cols\n",
    "model = ols(formula= formula, data=data_train).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference vs. Prediction\n",
    "- Inference: How does X affect y?\n",
    "    - figure out which features affect your outcome and how your outcome changes when these features change\n",
    "    - focused on only a subset of features\n",
    "    - great emphasis is given to the coefficients of these features as opposed to the overall model accuracy\n",
    "    - choose simpler, interpretable models like models: logistic regression, decision trees, linear SVMs \n",
    "- Prediction: How well can I use X to predict y?\n",
    "    - less concerned about how and which features impact Y as opposed to how you can efficiently use them to predict Y\n",
    "    - typically use all available features (and most likely engineer new features)\n",
    "    - less concerned about the coefficients of these features and instead focus on the overall model accuracy\n",
    "    - typically choose more complex, less interpretable models like SVMs with radial kernels, random forests, neural networks, and other techniques such regularization, cross-validation, grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Fit in Lin Reg\n",
    "- $R^2$ increases each time we add a new predictor -- even if this new predictor doesn't add any new information to the model. Model tends to overfit if we only use $R^2$ as our model fitting criterion. This is why train-test split is essential and why regularization techniques are used to refine more advanced regression models. Make sure to read [this blogpost](https://www.statisticshowto.datasciencecentral.com/adjusted-r2/) on the difference between the two to get a better sense to why use $R^2_{adj}$ !\n",
    "- **Stepwise selection**: start with an empty model (which only includes the intercept), and each time, the variable that has an associated parameter estimate with the lowest p-value is added to the model (forward step). After adding each new variable in the model, the algorithm will look at the p-values of all the other parameter estimates which were added to the model previously, and remove them if the p-value exceeds a certain value (backward step). The algorithm stops when no variables can be added or removed given the threshold values. \n",
    "- **Feature ranking with recursive feature elimination**: Scikit-learn also provides a few [functionalities for feature selection](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection). Their *Feature Ranking with Recursive Feature Elimination* selects the pre-specified $n$ most important features. This means you must specify the number of features to retail. If this number is not provided, half are used by default. See [here](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html) for more information on how the algorithm works.\n",
    "- **Forward selection using adjusted R-squared**: [This resource](https://planspace.org/20150423-forward_selection_with_statsmodels/) provides code for a forward selection procedure (much like stepwise selection, but without a backward pass), but this time looking at the adjusted R-squared to make decisions on which variable to add to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "result = stepwise_selection(predictors, data_fin['mpg'], verbose=True)\n",
    "print('resulting features:')\n",
    "print(result)\n",
    "# or RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "selector = RFE(linreg, n_features_to_select=3)\n",
    "selector = selector.fit(predictors, data_fin['mpg'])\n",
    "selector.support_\n",
    "selector.ranking_\n",
    "estimators = selector.estimator_\n",
    "print(estimators.coef_)\n",
    "print(estimators.intercept_)\n",
    "\n",
    "# Example (LAB)\n",
    "result = stepwise_selection(X, y, verbose=False);\n",
    "import statsmodels.api as sm\n",
    "X_fin = X[result]\n",
    "X_with_intercept = sm.add_constant(X_fin)\n",
    "model = sm.OLS(y,X_with_intercept).fit()\n",
    "model.summary()\n",
    "# or\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "selector = RFE(linreg, n_features_to_select = 5)\n",
    "selector = selector.fit(X, y.values.ravel()) # convert y to 1d np array to prevent DataConversionWarning\n",
    "selector.support_\n",
    "selected_columns = X.columns[selector.support_]\n",
    "linreg.fit(X[selected_columns],y)\n",
    "yhat = linreg.predict(X[selected_columns])\n",
    "SS_Residual = np.sum((y-yhat)**2)\n",
    "SS_Total = np.sum((y-np.mean(y))**2)\n",
    "r_squared = 1 - SS_Residual/SS_Total\n",
    "adjusted_r_squared = 1 - (1-r_squared)*(len(y)-1)/(len(y)-X[selected_columns].shape[1]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Model Validation\n",
    "Residuals:\n",
    "\n",
    "$r_{i,train} = y_{i,train} - \\hat y_{i,train}$ \n",
    "\n",
    "$r_{i,test} = y_{i,test} - \\hat y_{i,test}$ \n",
    "\n",
    "To get a summarized measure over all the instances in the test set and training set, a popular metric is the (Root) Mean Squared Error:\n",
    "\n",
    "RMSE = $\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_{i} - \\hat y_{i})^2}$\n",
    "\n",
    "MSE = $\\frac{1}{n}\\sum_{i=1}^{n}(y_{i} - \\hat y_{i})^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "y_hat_train = linreg.predict(X_train)\n",
    "y_hat_test = linreg.predict(X_test)\n",
    "\n",
    "train_residuals = y_hat_train - y_train\n",
    "test_residuals = y_hat_test - y_test\n",
    "\n",
    "mse_train = np.sum((y_train-y_hat_train)**2)/len(y_train)\n",
    "mse_test = np.sum((y_test-y_hat_test)**2)/len(y_test)\n",
    "print('Train Mean Squarred Error:', mse_train)\n",
    "print('Test Mean Squarred Error:', mse_test)\n",
    "print('RMSE Train:', np.sqrt(mse_train))\n",
    "print('RMSE Test:', np.sqrt(mse_test))\n",
    "# or\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "train_mse = mean_squared_error(y_train, y_hat_train)\n",
    "test_mse = mean_squared_error(y_test, y_hat_test)\n",
    "print('Train Mean Squarred Error:', train_mse)\n",
    "print('Test Mean Squarred Error:', test_mse\n",
    "print('RMSE Train:', np.sqrt(train_mse))\n",
    "print('RMSE Test:', np.sqrt(test_mse))\n",
    "r2_score(y_test, y_hat_test)\n",
    "      \n",
    "      \n",
    "# LAB\n",
    "# Evaluate the effect of train-test split size\n",
    "\n",
    "import random\n",
    "random.seed(110)\n",
    "\n",
    "train_err = []\n",
    "test_err = []\n",
    "t_sizes = list(range(5,100,5))\n",
    "for t_size in t_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=t_size/100)\n",
    "    linreg.fit(X_train, y_train)\n",
    "    y_hat_train = linreg.predict(X_train)\n",
    "    y_hat_test = linreg.predict(X_test)\n",
    "    train_err.append(mean_squared_error(y_train, y_hat_train))\n",
    "    test_err.append(mean_squared_error(y_test, y_hat_test))\n",
    "plt.scatter(t_sizes, train_err, label='Training Error')\n",
    "plt.scatter(t_sizes, test_err, label='Testing Error')\n",
    "plt.legend()\n",
    "      \n",
    "# or cell below\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the previous example, but for each train-test split size, generate 10 iterations of models/errors and save the average train/test error. This will help account for any particularly good/bad models that might have resulted from poor/good splits in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(900)\n",
    "train_err = []\n",
    "test_err = []\n",
    "t_sizes = range(5,100,5)\n",
    "for t_size in t_sizes:\n",
    "    temp_train_err = []\n",
    "    temp_test_err = []\n",
    "    for i in range(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=t_size/100)\n",
    "        linreg.fit(X_train, y_train)\n",
    "        y_hat_train = linreg.predict(X_train)\n",
    "        y_hat_test = linreg.predict(X_test)\n",
    "        temp_train_err.append(mean_squared_error(y_train, y_hat_train))\n",
    "        temp_test_err.append(mean_squared_error(y_test, y_hat_test))\n",
    "    train_err.append(np.mean(temp_train_err))\n",
    "    test_err.append(np.mean(temp_test_err))\n",
    "plt.scatter(t_sizes, train_err, label='Training Error')\n",
    "plt.scatter(t_sizes, test_err, label='Testing Error')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intro to Cross Validation + Lab\n",
    "When using train-test split, random samples of data are created for the training and the test set. The problem with this is that the training and test MSE strongly depend on how the training and test sets were created.\n",
    "\n",
    "There are many ways to perform cross-validation, and we strongly recommend you have a look at the [Cross-validation documentation in Scikit-Learn](http://scikit-learn.org/stable/modules/cross_validation.html) and \n",
    "[scoring parameter](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T01:21:28.898364Z",
     "start_time": "2021-01-14T01:21:19.664159Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cv_5_results  = np.mean(cross_val_score(linreg, X, y, cv=5,  scoring='neg_mean_squared_error'))\n",
    "cv_10_results = np.mean(cross_val_score(linreg, X, y, cv=10, scoring='neg_mean_squared_error'))\n",
    "cv_20_results = np.mean(cross_val_score(linreg, X, y, cv=20, scoring='neg_mean_squared_error'))\n",
    "cv_5_results.mean()\n",
    "# or\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "mse = make_scorer(mean_squared_error)\n",
    "cv_5_results = cross_val_score(linreg, X, y, cv=5, scoring=mse)\n",
    "cv_5_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coeff. of Deter.\n",
    "- \"R-Squared\": =statistical **measure** that is used to assess the **goodness of fit** of a regression model\n",
    "- R^2% of the variations in y are explained by the X in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model.summary()\n",
    "\n",
    "Here is a brief description of these measures:\n",
    "\n",
    "The left part of the first table gives some specifics on the data and the model:\n",
    "\n",
    "* **Dep. Variable**: Singular. Which variable is the point of interest of the model\n",
    "* **Model**: Technique used, an abbreviated version of Method (see methods for more).\n",
    "* **Method**: The loss function optimized in the parameter selection process. Least Squares since it picks the parameters that reduce the training error. This is also known as Mean Square Error [MSE].\n",
    "* **No. Observations**: The number of observations used by the model, or size of the training data.\n",
    "* **Degrees of Freedom Residuals**: Degrees of freedom of the residuals, which is the number of observations – number of parameters. Intercept is a parameter. The purpose of Degrees of Freedom is to reflect the impact of descriptive/summarizing statistics in the model, which in regression is the coefficient. Since the observations must \"live up\" to these parameters, they only have so many free observations, and the rest must be reserved to \"live up\" to the parameters' prophecy. This internal mechanism ensures that there are enough observations to match the parameters.\n",
    "* **Degrees of Freedom Model**: The number of parameters in the model (not including the constant/intercept term if present)\n",
    "* **Covariance Type**: Robust regression methods are designed to be not overly affected by violations of assumptions by the underlying data-generating process. Since this model is Ordinary Least Squares, it is non-robust and therefore highly sensitive to outliers.\n",
    "\n",
    "The right part of the first table shows the goodness of fit: \n",
    "\n",
    "* **R-squared**: The coefficient of determination, the Sum Squares of Regression divided by Total Sum Squares. This translates to the percent of variance explained by the model. The remaining percentage represents the variance explained by error, the E term, the part that model and predictors fail to grasp.\n",
    "* **Adj. R-squared**: Version of the R-Squared that penalizes additional independent variables. \n",
    "* **F-statistic**: A measure of how significant the fit is. The mean squared error of the model divided by the mean squared error of the residuals. Feeds into the calculation of the P-Value.\n",
    "* **Prob (F-statistic) or P-Value**: The probability that a sample like this would yield the above statistic, and whether the model's verdict on the null hypothesis will consistently represent the population. Does not measure effect magnitude, instead measures the integrity and consistency of this test on this group of data.\n",
    "* **Log-likelihood**: The log of the likelihood function.\n",
    "* **AIC**: The Akaike Information Criterion. Adjusts the log-likelihood based on the number of observations and the complexity of the model. Penalizes the model selection metrics when more independent variables are added.\n",
    "* **BIC**: The Bayesian Information Criterion. Similar to the AIC, but has a higher penalty for models with more parameters. Penalizes the model selection metrics when more independent variables are added.\n",
    "\n",
    "The second table shows the coefficient report: \n",
    "\n",
    "* **coef**: The estimated value of the coefficient. By how much the model multiplies the independent value by.\n",
    "* **std err**: The basic standard error of the estimate of the coefficient. Average distance deviation of the points from the model, which offers a unit relevant way to gauge model accuracy.\n",
    "* **t**: The t-statistic value. This is a measure of how statistically significant the coefficient is.\n",
    "* **P > |t|**: P-value that the null-hypothesis that the coefficient = 0 is true. If it is less than the confidence level, often 0.05, it indicates that there is a statistically significant relationship between the term and the response.\n",
    "* **[95.0% Conf. Interval]**: The lower and upper values of the 95% confidence interval. Specific range of the possible coefficient values.\n",
    "\n",
    "The third table shows information about the residuals, autocorrelation, and multicollinearity: \n",
    "\n",
    "* **Skewness**: A measure of the symmetry of the data about the mean. Normally-distributed errors should be symmetrically distributed about the mean (equal amounts above and below the line). The normal distribution has 0 skew.\n",
    "* **Kurtosis**: A measure of the shape of the distribution. Compares the amount of data close to the mean with those far away from the mean (in the tails), so model \"peakiness\". The normal distribution has a Kurtosis of 3, and the greater the number, the more the curve peaks.\n",
    "* **Omnibus D’Angostino’s test**: Provides a combined statistical test for the presence of skewness and kurtosis.\n",
    "* **Prob(Omnibus)**: The above statistic turned into a probability\n",
    "* **Jarque-Bera**: A different test of the skewness and kurtosis\n",
    "* **Prob (JB)**: The above statistic turned into a probability\n",
    "* **Durbin-Watson**: A test for the presence of autocorrelation (that the errors are not independent), which is often important in time-series analysis\n",
    "* **Cond. No**: A test for multicollinearity (if in a fit with multiple parameters, the parameters are related to each other).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fig = sm.graphics.plot_regress_exog(model, \"height\", fig=fig)\n",
    "\n",
    "For the four graphs we see above:\n",
    "\n",
    "* The **Y and Fitted vs. X** graph plots the dependent variable against our predicted values with a confidence interval. The positive relationship shows that height and weight are correlated, i.e., when one variable increases the other increases.\n",
    "\n",
    "* The **Residuals versus height** graph shows our model's errors versus the specified predictor variable. Each dot is an observed value; the line represents the mean of those observed values. Since there's no pattern in the distance between the dots and the mean value, the OLS assumption of homoskedasticity holds.\n",
    "\n",
    "* The **Partial regression plot** shows the relationship between height and weight, taking in to account the impact of adding other independent variables on our existing height coefficient. You'll later learn how this same graph changes when you add more variables.\n",
    "\n",
    "* The **Component and Component Plus Residual (CCPR)** plot is an extension of the partial regression plot. It shows where the trend line would lie after adding the impact of adding our other independent variables on the weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Popular Transformations\n",
    "Log transformation\n",
    "\n",
    "As seen in the previous lesson, a log transformation is a very useful tool when you have data that clearly does not follow a normal distribution. Log transformation can help reduce skewness when you have skewed data, and can help reducing variability of data. \n",
    "\n",
    "\n",
    "Min-max scaling\n",
    "\n",
    "When performing min-max scaling, you can transform x to get the transformed $x'$ by using the formula:\n",
    "\n",
    "$$x' = \\dfrac{x - \\min(x)}{\\max(x)-\\min(x)}$$\n",
    "\n",
    "This way of scaling brings all values between 0 and 1. \n",
    "\n",
    "Standardization\n",
    "\n",
    "When \n",
    "\n",
    "$$x' = \\dfrac{x - \\bar x}{\\sigma}$$\n",
    "\n",
    "x' will have mean $\\mu = 0$ and $\\sigma = 1$\n",
    "\n",
    "Note that standardization does not make data $more$ normal, it will just change the mean and the standard error!\n",
    "\n",
    "Mean normalization\n",
    "When performing mean normalization, you use the following formula:\n",
    "$$x' = \\dfrac{x - \\text{mean}(x)}{\\max(x)-\\min(x)}$$\n",
    "\n",
    "The distribution will have values between -1 and 1, and a mean of 0.\n",
    "\n",
    "Unit vector transformation\n",
    " When performing unit vector transformations, you can create a new variable x' with a range [0,1]:\n",
    " \n",
    "$$x'= \\dfrac{x}{{||x||}}$$\n",
    "\n",
    "\n",
    "Recall that the norm of x $||x||= \\sqrt{(x_1^2+x_2^2+...+x_n^2)}$\n",
    "\n",
    "Scikit-learn provides automatic tools to scale features, see, among others, `MinMaxScaler`, `StandardScaler`, \n",
    "and `Normalizer`. Have a look at these built-in functions and some code examples here: http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General workflow\n",
    "**O**btain Data:\n",
    "- quick preview of data and business understanding\n",
    "\n",
    "**S**crub/Clean Data:\n",
    "- Drop duplicate rows/id's appropriately\n",
    "- Deal w/ Data Types:\n",
    "    - investigate string objects like value counts, hidden missing values, etc.\n",
    "    - dates\n",
    "- Deal with missing values and fill appropriately\n",
    "- Deal w/ outliers and extraneous values\n",
    "    - check descriptive stats\n",
    "- Bin/cut cat vars and create new features if necessary\n",
    "    - check distributions/hists\n",
    "- Investigate/deal with multicollinearity\n",
    "    - remove columns if necessary\n",
    "- Save cleaned data to csv\n",
    "\n",
    "**E**DA:\n",
    "- Load clean data/preview\n",
    "- Explore y variable for outliers and distribution (with boxplot and/or histogram)\n",
    "    - address issues if necessary\n",
    "- Check heatmap for multicollinearity and strong correlations b/w price and the features\n",
    "    - note strong/weak feature candidates\n",
    "- Split continuous and categorical variables\n",
    "- Explore strong feature candidates with a scatter matrix\n",
    "    - focus on distributions (diagonal) and scatter plots with y on y-axis\n",
    "\n",
    "**M**odeling:\n",
    "- Feature Select\n",
    "- OHE cat vars\n",
    "- transform cont vars\n",
    "- Fit the model\n",
    "- Check assumptions\n",
    "    - multicollinearity\n",
    "        - check variation inflation factors or heat map\n",
    "            -  variance inflation factor shows if there is multicollinearity between our variables\n",
    "            - vif of 5 or greater (or more definitively 10 or greater) are displaying multicollinearity with other variables\n",
    "            - removing multicollinear features may hurt model performance\n",
    "    - linearity\n",
    "        - check scatter matrix or joint plot\n",
    "    - normality\n",
    "        - QQ-plot or JB test\n",
    "    - homsocedasticity\n",
    "        - scatterplot or GQ test (assumes normality\n",
    "- repeat the process by building a model with different features or refining the current model\n",
    "\n",
    "I**N**terpret results:\n",
    "- Interpret statistics appropriately (R*2, errors, tests, coeffs, etc.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "227.273px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
