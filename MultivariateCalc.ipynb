{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Calculus\n",
    "## WK3\n",
    "#### PQ: Training Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T14:56:31.172293Z",
     "start_time": "2021-01-10T14:56:30.353681Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 1. Cost function for single neural link\n",
    "\n",
    "# First we set the state of the network\n",
    "σ = np.tanh\n",
    "w1 = 1.3\n",
    "b1 = -0.1\n",
    "\n",
    "# Then define the neuron activation.\n",
    "def a1(a0) :\n",
    "    z = w1 * a0 + b1\n",
    "    return σ(z)\n",
    "\n",
    "x = 0\n",
    "a1(0)\n",
    "C0 = (a1(0) - 1) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Derivative of individual cost functions\n",
    "\n",
    "# First define our sigma function.\n",
    "sigma = np.tanh\n",
    "\n",
    "# Next define the feed-forward equation.\n",
    "def a1 (w1, b1, a0) :\n",
    "    z = w1 * a0 + b1\n",
    "    return sigma(z)\n",
    "\n",
    "# The individual cost function is the square of the difference between\n",
    "# the network output and the training data output.\n",
    "def C (w1, b1, x, y) :\n",
    "    return (a1(w1, b1, x) - y)**2\n",
    "\n",
    "# This function returns the derivative of the cost function with\n",
    "# respect to the weight.\n",
    "def dCdw (w1, b1, x, y) :\n",
    "    z = w1 * x + b1\n",
    "    dCda = 2 * (a1(w1, b1, x) - y) # Derivative of cost with activation\n",
    "    dadz = 1/np.cosh(z)**2 # derivative of activation with weighted sum z\n",
    "    dzdw = x # derivative of weighted sum z with weight\n",
    "    return dCda * dadz * dzdw # Return the chain rule product.\n",
    "\n",
    "# This function returns the derivative of the cost function with\n",
    "# respect to the bias.\n",
    "# It is very similar to the previous function.\n",
    "def dCdb (w1, b1, x, y) :\n",
    "    z = w1 * x + b1\n",
    "    dCda = 2 * (a1(w1, b1, x) - y)\n",
    "    dadz = 1/np.cosh(z)**2\n",
    "    dzdb = 1\n",
    "    return dCda * dadz * dzdb\n",
    "\n",
    "# Test with an unfit weight and bias.\n",
    "w1 = 2.3\n",
    "b1 = -1.2\n",
    "# Test on a single data point pair of x and y.\n",
    "x = 0\n",
    "y = 1\n",
    "# Output how the cost would change in proportion to a small change in the bias\n",
    "print( dCdw(w1, b1, x, y) )\n",
    "print( dCdb(w1, b1, x, y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Derivative of cost function in vector form using modulus squared\n",
    "\n",
    "# Define the activation function.\n",
    "sigma = np.tanh\n",
    "\n",
    "# Use a random initial weight and bias.\n",
    "W = np.array([[-0.94529712, -0.2667356 , -0.91219181],\n",
    "              [ 2.05529992,  1.21797092,  0.22914497]])\n",
    "b = np.array([ 0.61273249,  1.6422662 ])\n",
    "\n",
    "# define our feed forward function\n",
    "def a1 (a0) :\n",
    "  # Notice the next line is almost the same as previously,\n",
    "  # except we are using matrix multiplication rather than scalar multiplication\n",
    "  # hence the '@' operator, and not the '*' operator.\n",
    "  z = W @ a0 + b\n",
    "  # Everything else is the same though,\n",
    "  return sigma(z)\n",
    "\n",
    "# Next, if a training example is,\n",
    "x = np.array([0.7, 0.6, 0.2])\n",
    "y = np.array([0.9, 0.6])\n",
    "\n",
    "# Then the cost function is,\n",
    "d = a1(x) - y # Vector difference between observed and expected activation\n",
    "C = d @ d # Absolute value squared of the difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LAB: Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PACKAGE\n",
    "# First load the worksheet dependencies.\n",
    "# Here is the activation function and its derivative.\n",
    "sigma = lambda z : 1 / (1 + np.exp(-z))\n",
    "d_sigma = lambda z : np.cosh(z/2)**(-2) / 4\n",
    "\n",
    "# This function initialises the network with it's structure, it also resets any training already done.\n",
    "def reset_network (n1 = 6, n2 = 7, random=np.random) :\n",
    "    global W1, W2, W3, b1, b2, b3\n",
    "    W1 = random.randn(n1, 1) / 2\n",
    "    W2 = random.randn(n2, n1) / 2\n",
    "    W3 = random.randn(2, n2) / 2\n",
    "    b1 = random.randn(n1, 1) / 2\n",
    "    b2 = random.randn(n2, 1) / 2\n",
    "    b3 = random.randn(2, 1) / 2\n",
    "\n",
    "# This function feeds forward each activation to the next layer. It returns all weighted sums and activations.\n",
    "def network_function(a0) :\n",
    "    z1 = W1 @ a0 + b1\n",
    "    a1 = sigma(z1)\n",
    "    z2 = W2 @ a1 + b2\n",
    "    a2 = sigma(z2)\n",
    "    z3 = W3 @ a2 + b3\n",
    "    a3 = sigma(z3)\n",
    "    return a0, z1, a1, z2, a2, z3, a3\n",
    "\n",
    "# This is the cost function of a neural network with respect to a training set.\n",
    "def cost(x, y) :\n",
    "    return np.linalg.norm(network_function(x)[-1] - y)**2 / x.size\n",
    "\n",
    "#######################################################################################################################\n",
    "# Jacobian for the third layer weights. There is no need to edit this function.\n",
    "def J_W3 (x, y) :\n",
    "    # First get all the activations and weighted sums at each layer of the network.\n",
    "    a0, z1, a1, z2, a2, z3, a3 = network_function(x)\n",
    "    # We'll use the variable J to store parts of our result as we go along, updating it in each line.\n",
    "    # Firstly, we calculate dC/da3, using the expressions above.\n",
    "    J = 2 * (a3 - y)\n",
    "    # Next multiply the result we've calculated by the derivative of sigma, evaluated at z3.\n",
    "    J = J * d_sigma(z3)\n",
    "    # Then we take the dot product (along the axis that holds the training examples) with the final partial derivative,\n",
    "    # i.e. dz3/dW3 = a2\n",
    "    # and divide by the number of training examples, for the average over all training examples.\n",
    "    J = J @ a2.T / x.size\n",
    "    # Finally return the result out of the function.\n",
    "    return J\n",
    "\n",
    "# In this function, you will implement the jacobian for the bias.\n",
    "# As you will see from the partial derivatives, only the last partial derivative is different.\n",
    "# The first two partial derivatives are the same as previously.\n",
    "# ===YOU SHOULD EDIT THIS FUNCTION===\n",
    "def J_b3 (x, y) :\n",
    "    # As last time, we'll first set up the activations.\n",
    "    a0, z1, a1, z2, a2, z3, a3 = network_function(x)\n",
    "    # Next you should implement the first two partial derivatives of the Jacobian.\n",
    "    # ===COPY TWO LINES FROM THE PREVIOUS FUNCTION TO SET UP THE FIRST TWO JACOBIAN TERMS===\n",
    "    J =\n",
    "    J =\n",
    "    # For the final line, we don't need to multiply by dz3/db3, because that is multiplying by 1.\n",
    "    # We still need to sum over all training examples however.\n",
    "    # There is no need to edit this line.\n",
    "    J = np.sum(J, axis=1, keepdims=True) / x.size\n",
    "    return J\n",
    "\n",
    "#######################################################################################################################\n",
    "# Compare this function to J_W3 to see how it changes.\n",
    "# There is no need to edit this function.\n",
    "def J_W2 (x, y) :\n",
    "    #The first two lines are identical to in J_W3.\n",
    "    a0, z1, a1, z2, a2, z3, a3 = network_function(x)    \n",
    "    J = 2 * (a3 - y)\n",
    "    # the next two lines implement da3/da2, first σ' and then W3.\n",
    "    J = J * d_sigma(z3)\n",
    "    J = (J.T @ W3).T\n",
    "    # then the final lines are the same as in J_W3 but with the layer number bumped down.\n",
    "    J = J * d_sigma(z2)\n",
    "    J = J @ a1.T / x.size\n",
    "    return J\n",
    "\n",
    "# As previously, fill in all the incomplete lines.\n",
    "# ===YOU SHOULD EDIT THIS FUNCTION===\n",
    "def J_b2 (x, y) :\n",
    "    a0, z1, a1, z2, a2, z3, a3 = network_function(x)\n",
    "    J = 2 * (a3 - y)\n",
    "    J =\n",
    "    J =\n",
    "    J =\n",
    "    J = np.sum(J, axis=1, keepdims=True) / x.size\n",
    "    return J\n",
    "\n",
    "#######################################################################################################################\n",
    "# Fill in all incomplete lines.\n",
    "# ===YOU SHOULD EDIT THIS FUNCTION===\n",
    "def J_W1 (x, y) :\n",
    "    a0, z1, a1, z2, a2, z3, a3 = network_function(x)\n",
    "    J =\n",
    "    J =\n",
    "    J =\n",
    "    J =\n",
    "    J =\n",
    "    J =\n",
    "    J = J @ a0.T / x.size\n",
    "    return J\n",
    "\n",
    "# Fill in all incomplete lines.\n",
    "# ===YOU SHOULD EDIT THIS FUNCTION===\n",
    "def J_b1 (x, y) :\n",
    "    a0, z1, a1, z2, a2, z3, a3 = network_function(x)\n",
    "    J =\n",
    "    J =\n",
    "    J =\n",
    "    J =\n",
    "    J =\n",
    "    J =\n",
    "    J = np.sum(J, axis=1, keepdims=True) / x.size\n",
    "    return J\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>\n",
    "\n",
    "## WK4\n",
    "#### LAB: Gram-Schmidt Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>\n",
    "\n",
    "## WK5\n",
    "#### PQ: eigen-things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T09:01:33.024117Z",
     "start_time": "2021-01-08T09:01:33.019684Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2.]),\n",
       " array([[1., 0.],\n",
       "        [0., 1.]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2\n",
    "ev2 = np.linalg.eig(np.array([[1,0],[0,2]]))\n",
    "ev2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T09:06:33.322245Z",
     "start_time": "2021-01-08T09:06:33.317324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3., 5.]),\n",
       " array([[1.        , 0.89442719],\n",
       "        [0.        , 0.4472136 ]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4\n",
    "ev4 = np.linalg.eig(np.array([[3,4],[0,5]]))\n",
    "ev4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T09:09:49.556945Z",
     "start_time": "2021-01-08T09:09:49.552297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4., 1.]),\n",
       " array([[0.        , 0.9486833 ],\n",
       "        [1.        , 0.31622777]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6\n",
    "ev6 = np.linalg.eig(np.array([[1,0],[-1,4]]))\n",
    "ev6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T09:12:46.128179Z",
     "start_time": "2021-01-08T09:12:46.123972Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-5.,  5.]),\n",
       " array([[-0.9701425 , -0.70710678],\n",
       "        [ 0.24253563, -0.70710678]]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8\n",
    "ev8 = np.linalg.eig(np.array([[-3,8],[2,3]]))\n",
    "ev8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T09:17:00.223173Z",
     "start_time": "2021-01-08T09:17:00.197397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.+2.98023224e-08j, 1.-2.98023224e-08j]),\n",
       " array([[ 0.70710678+0.00000000e+00j,  0.70710678-0.00000000e+00j],\n",
       "        [-0.70710678+5.26835606e-09j, -0.70710678-5.26835606e-09j]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9\n",
    "ev9 = np.linalg.eig(np.array([[5,4],[-4,-3]]))\n",
    "ev9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T09:18:16.062285Z",
     "start_time": "2021-01-08T09:18:16.057627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.5+0.8660254j, -0.5-0.8660254j]),\n",
       " array([[ 0.8660254+0.j  ,  0.8660254-0.j  ],\n",
       "        [-0.4330127-0.25j, -0.4330127+0.25j]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10\n",
    "ev10 = np.linalg.eig(np.array([[-2,-3],[1,1]]))\n",
    "ev10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>\n",
    "\n",
    "#### PQ: Diagonalization and Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T10:09:34.920310Z",
     "start_time": "2021-01-08T10:09:34.915241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 6, -1],\n",
       "        [ 2,  3]]),\n",
       " array([[0.70710678, 0.4472136 ],\n",
       "        [0.70710678, 0.89442719]]),\n",
       " array([[ 2.82842712, -1.41421356],\n",
       "        [-2.23606798,  2.23606798]]),\n",
       " array([[5.0000000e+00, 8.8817842e-16],\n",
       "        [0.0000000e+00, 4.0000000e+00]]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1\n",
    "T = np.array([[6,-1],[2,3]])\n",
    "C = np.linalg.eig(T)[1]\n",
    "invC = np.linalg.inv(C)\n",
    "D = invC @ T @ C\n",
    "T, C, invC, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T10:10:49.127920Z",
     "start_time": "2021-01-08T10:10:49.122835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2,  7],\n",
       "        [ 0, -1]]),\n",
       " array([[ 1.        , -0.91914503],\n",
       "        [ 0.        ,  0.3939193 ]]),\n",
       " array([[1.        , 2.33333333],\n",
       "        [0.        , 2.53859104]]),\n",
       " array([[ 2.0000000e+00, -4.4408921e-16],\n",
       "        [ 0.0000000e+00, -1.0000000e+00]]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2\n",
    "T = np.array([[2,7],[0,-1]])\n",
    "C = np.linalg.eig(T)[1]\n",
    "invC = np.linalg.inv(C)\n",
    "D = invC @ T @ C\n",
    "T, C, invC, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T10:13:52.237486Z",
     "start_time": "2021-01-08T10:13:52.232347Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1,  0],\n",
       "        [ 2, -1]]),\n",
       " array([[0.        , 0.70710678],\n",
       "        [1.        , 0.70710678]]),\n",
       " array([[-1.        ,  1.        ],\n",
       "        [ 1.41421356,  0.        ]]),\n",
       " array([[-1.,  0.],\n",
       "        [ 0.,  1.]]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3\n",
    "T = np.array([[1,0],[2,-1]])\n",
    "C = np.linalg.eig(T)[1]\n",
    "invC = np.linalg.inv(C)\n",
    "D = invC @ T @ C\n",
    "T, C, invC, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T10:19:51.791369Z",
     "start_time": "2021-01-08T10:19:51.786520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 0.],\n",
       "        [0., 1.]]),\n",
       " array([[1, 2],\n",
       "        [0, 1]]),\n",
       " array([[ 1., -2.],\n",
       "        [ 0.,  1.]]),\n",
       " array([[1., 0.],\n",
       "        [0., 1.]]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4\n",
    "C = np.array([[1,2],[0,1]])\n",
    "invC = np.linalg.inv(C)\n",
    "D = np.identity(2)\n",
    "T = C @ D @ invC\n",
    "T, C, invC, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T10:24:04.879377Z",
     "start_time": "2021-01-08T10:24:04.791740Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 6., -1.],\n",
       "        [ 2.,  3.]]),\n",
       " array([[1, 1],\n",
       "        [1, 2]]),\n",
       " array([[ 2., -1.],\n",
       "        [-1.,  1.]]),\n",
       " array([[5, 0],\n",
       "        [0, 4]]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5\n",
    "C = np.array([[1,1],[1,2]])\n",
    "invC = np.linalg.inv(C)\n",
    "D = np.array([[5,0],[0,4]])\n",
    "T = C @ D @ invC\n",
    "T, C, invC, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T10:29:33.593401Z",
     "start_time": "2021-01-08T10:29:33.589006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[186., -61.],\n",
       "        [122.,   3.]]),\n",
       " array([[216.,  -1.],\n",
       "        [  8.,  27.]]),\n",
       " array([[186., -61.],\n",
       "        [122.,   3.]]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T3 = C @ D ** 3 @ invC\n",
    "T3, T ** 3, T @ T @ T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T10:30:44.695752Z",
     "start_time": "2021-01-08T10:30:44.690289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2.,  7.],\n",
       "        [ 0., -1.]]),\n",
       " array([[ 7,  1],\n",
       "        [-3,  0]]),\n",
       " array([[ 0.        , -0.33333333],\n",
       "        [ 1.        ,  2.33333333]]),\n",
       " array([[-1,  0],\n",
       "        [ 0,  2]]),\n",
       " array([[ 8., 21.],\n",
       "        [ 0., -1.]]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6\n",
    "C = np.array([[7,1],[-3,0]])\n",
    "invC = np.linalg.inv(C)\n",
    "D = np.array([[-1,0],[0,2]])\n",
    "T = C @ D @ invC\n",
    "T, C, invC, D, T @ T @ T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T10:32:01.343058Z",
     "start_time": "2021-01-08T10:32:01.337764Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.,  0.],\n",
       "        [ 2., -1.]]),\n",
       " array([[1, 0],\n",
       "        [1, 1]]),\n",
       " array([[ 1.,  0.],\n",
       "        [-1.,  1.]]),\n",
       " array([[ 1,  0],\n",
       "        [ 0, -1]]),\n",
       " array([[ 1.,  0.],\n",
       "        [ 2., -1.]]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7\n",
    "C = np.array([[1,0],[1,1]])\n",
    "invC = np.linalg.inv(C)\n",
    "D = np.array([[1,0],[0,-1]])\n",
    "T = C @ D @ invC\n",
    "T, C, invC, D, T @ T @ T @ T @ T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LAB:  PageRank algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T14:49:53.139476Z",
     "start_time": "2021-01-10T14:49:53.137103Z"
    }
   },
   "source": [
    "#### QUIZ:  Eigen-things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
